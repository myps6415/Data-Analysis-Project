{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "依照[政大 Python AI 深度學習達人的第一堂課](http://moocs.nccu.edu.tw/media/23095)課程進行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KERAS_BACKEND=tensorflow\n"
     ]
    }
   ],
   "source": [
    "%env KERAS_BACKEND=tensorflow\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# keras function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# keras dataset\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# keras utilis function (one hot encoding)\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讀取 MNIST 資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 輸入格式整理\n",
    "原本每筆數據是 28 * 28 的矩陣，但標準神經網路只吃平的，每次要 28 * 28 = 784 長的像量，因此 reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取訓練和測試資料的數字為 0, 1 的資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_01 = x_train[y_train <= 1]\n",
    "x_test_01 = x_test[y_test <= 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將 label 轉換為 one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_10 = np_utils.to_categorical(y_train, 10)\n",
    "y_test_10 = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "y_train_01 = y_train[y_train <= 1]\n",
    "y_train_01 = np_utils.to_categorical(y_train_01, 2)\n",
    "\n",
    "y_test_01 = y_test[y_test <= 1]\n",
    "y_test_01 = np_utils.to_categorical(y_test_01, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "適時確認資料的大小確保資料的一致性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12665, 784), (2115, 784))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_01.shape, x_test_01.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12665, 2), (2115, 2))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_01.shape, y_test_01.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回顧 Sequential API\n",
    "以下列方式建立一個具有下列的設定\n",
    "* 使用 2 個 hidden layers\n",
    "* 每個 hidden layer 用 500 個神經元\n",
    "* Activation Function 唯一指名 sigmoid\n",
    "\n",
    "的神經網路，建立指令是透過建立 `Sequential()` 和 `.add` 的方式逐層建立，如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/john.tung/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5010      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 648,010\n",
      "Trainable params: 648,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Construct a sandbox to put layers inside\n",
    "model = Sequential()\n",
    "\n",
    "# Put fully-connected layers (Dense) inside\n",
    "model.add(Dense(500, input_dim=784))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(500))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 觀察 model.layers\n",
    "觀察 `model.layers`，可以發現 `model` 其實就是一堆神經網路層疊起來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.Dense at 0x647672fd0>,\n",
       " <keras.layers.core.Activation at 0x6422a1c90>,\n",
       " <keras.layers.core.Dense at 0x6476d1d10>,\n",
       " <keras.layers.core.Activation at 0x6482b9b50>,\n",
       " <keras.layers.core.Dense at 0x6482b9890>,\n",
       " <keras.layers.core.Activation at 0x64824ba90>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "換言之，每個 `.add` 其實在做的事情就是\n",
    "\n",
    "`model.add(Dense(500, input_dim=784))` 是將 `<keras.layers.core.Dense at 0x647672fd0>` 加進 model.layers\n",
    "\n",
    "`model.add(Activation('sigmoid'))` 將 `<keras.layers.core.Activation at 0x6422a1c90>` 加進 model.layers\n",
    "\n",
    "... 以此類推\n",
    "\n",
    "## 以 list 的形式使用 Sequential API\n",
    "神經網路是將隱藏曾逐層堆疊在一起的 list，因此也可以 list 的形式建立相同的神經網路\n",
    "首先將兩個隱藏層及其 Activation Function 分別寫在 list 中，如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_layer = [Dense(500, input_dim=784),\n",
    "              Activation('sigmoid')]\n",
    "\n",
    "second_layer = [Dense(500),\n",
    "               Activation('sigmoid')]\n",
    "\n",
    "output_layer = [Dense(10),\n",
    "               Activation('softmax')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "從基本的 Python 資料結構中，我們知道 list 可以用 `+` 來進行合併，所以先看三個 list 合併後的樣子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.Dense at 0x647c5b950>,\n",
       " <keras.layers.core.Activation at 0x647c5b890>,\n",
       " <keras.layers.core.Dense at 0x647dd7d50>,\n",
       " <keras.layers.core.Activation at 0x64829ce10>,\n",
       " <keras.layers.core.Dense at 0x647c5bb50>,\n",
       " <keras.layers.core.Activation at 0x647a43690>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_layer + second_layer + output_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "合併起來的 list 看起來和某個 `model.layers` 一樣，接著要做的就是讓這個 list 真的變成某個神經網路的 `.layers`\n",
    "\n",
    "將寫成 list 的隱藏層 `+` 寫來送進 `Sequential` 中即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                5010      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 648,010\n",
      "Trainable params: 648,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(first_layer + second_layer + output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataAnalysisEnv",
   "language": "python",
   "name": "dataanalysisenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
