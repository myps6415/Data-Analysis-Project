{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold, learning_curve, train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_selection import RFECV\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom IPython.display import display\nfrom IPython.display import display_html\ndef display_side_by_side(*args):\n    html_str=''\n    for df in args:\n        html_str+=df.to_html()\n    display_html(html_str.replace('table', 'table style=\"display:inline\"'), raw=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/titanic/train.csv')\ntest_df = pd.read_csv('/kaggle/input/titanic/test.csv')\ndata_df = train_df.append(test_df)\ndata_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data_df['Sex'], hue=data_df['Survived'])\ndata_df[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().round(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data_df['Pclass'], hue=data_df['Survived'])\ndata_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().round(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 將性別資料轉為 0 1，0 為女性，1 為男性\ndata_df['Sex_Code'] = data_df['Sex'].map({'female':0, 'male':1}).astype('int')\ndata_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 分開訓練和測試集\ntrain_df = data_df[:len(train_df)]\ntest_df = data_df[len(train_df):]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 生還與否設定為目標 Y，其餘為訓練資料 X\nX = train_df.drop(labels=['Survived', 'PassengerId'], axis=1)\nY = train_df['Survived']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show Bseline\nBase = ['Sex_Code', 'Pclass']\nBase_Model = RandomForestClassifier(random_state=2, n_estimators=250, min_samples_split=20, oob_score=True)\nBase_Model.fit(X[Base], Y)\nprint('Base oob score: %.5f' %(Base_Model.oob_score_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"Predict = Base_Model.predict(test_df[Base])\nPredict_result = pd.DataFrame({'PassengerId':test_df['PassengerId'], 'Survived':Predict}).astype(int)\nPredict_result.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"Predict_result.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 加入票價","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(18, 7))\ndata_df['Log_Fare'] = (data_df['Fare']+1).map(lambda x:np.log10(x) if x > 0 else 0)\nsns.boxplot(y='Pclass', x='Log_Fare', hue='Survived', data=data_df, orient='h',\n           ax=ax, palette='Set3')\nax.set_title('Log_Fare & Pclass vs Survived', fontsize=20)\npd.pivot_table(data_df, values=['Fare'], index=['Pclass'], columns=['Survived'], aggfunc='median').round(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"從表和圖中可以看出存活下來的乘客確實平均而言付出較高的票價，決定測試這個特徵\n然而，測試之前需要將票價切分成幾個區間，才不會讓模型 overfit 太嚴重\n如此問題就來了，切成幾塊比較合適呢?\n\n首先填補缺失值，由於只有一項，填入中位數","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# filling missing values\ndata_df['Fare'] = data_df['Fare'].fillna(data_df['Fare'].median())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"用極限的觀點來考慮區間切分問題 :\n   * 當切分的區間太少時，區間內的資料太多一起平均，這樣沒有辦法看出差異性，使得特徵失真\n   * 當切分區間太多時，一點點票價的不同，都影響了生存率的高低，如此一來很明顯地會overfitting，並且，切分區間趨近於無限大時，就回到了原本的數值特徵\n\n下列程式碼將票價分別切分成 4, 5, 6 的區間，並命名為新的特徵","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making Bins\ndata_df['FareBin_4'] = pd.qcut(data_df['Fare'], 4)\ndata_df['FareBin_5'] = pd.qcut(data_df['Fare'], 5)\ndata_df['FareBin_6'] = pd.qcut(data_df['Fare'], 6)\n\nlabel = LabelEncoder()\ndata_df['FareBin_Code_4'] = label.fit_transform(data_df['FareBin_4'])\ndata_df['FareBin_Code_5'] = label.fit_transform(data_df['FareBin_5'])\ndata_df['FareBin_Code_6'] = label.fit_transform(data_df['FareBin_6'])\n\n# cross tab\ndf_4 = pd.crosstab(data_df['FareBin_Code_4'],data_df['Pclass'])\ndf_5 = pd.crosstab(data_df['FareBin_Code_5'],data_df['Pclass'])\ndf_6 = pd.crosstab(data_df['FareBin_Code_6'],data_df['Pclass'])\n\ndisplay_side_by_side(df_4, df_5, df_6)\n\n# plots\nfig, [ax1, ax2, ax3] = plt.subplots(1, 3,sharey=True)\n# fig.set_figwidth(18)\nfor axi in [ax1, ax2, ax3]:\n    axi.axhline(0.5,linestyle='dashed', c='black', alpha = .3)\ng1 = sns.factorplot(x='FareBin_Code_4', y=\"Survived\", data=data_df,kind='bar', ax=ax1)\ng2 = sns.factorplot(x='FareBin_Code_5', y=\"Survived\", data=data_df,kind='bar', ax=ax2)\ng3 = sns.factorplot(x='FareBin_Code_6', y=\"Survived\", data=data_df,kind='bar', ax=ax3)\n# close FacetGrid object\n# plt.close(g1.fig)\n# plt.close(g2.fig)\n# plt.close(g3.fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Pandas 中提供了蠻多種切分數值特徵的方式，這裡選用 qcut，qcut 是以累積百分比來切分的\n\n例如將副指令 = 4，就會以 0% ~ 25%, 25% ~ 50%, 50% ~ 75%, 75% ~ 100% 來切分資料\n\n好處是我們可以避免某個區間內的資料過少(skew problem)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# splits again beacuse we just engineered new feature\ntrain_df = data_df[:len(train_df)]\ntest_df = data_df[len(train_df):]\n\n# Training set and labels\nX = train_df.drop(labels=['Survived', 'PassengerId'],axis=1)\nY = train_df['Survived']\n\n# show columns\nX.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"對於特徵選擇 (Feature Slection) 的問題\n\n這裡利用前向選擇法 (RFE) 做特徵選擇\n\n特徵選擇的方法我們有幾個選項，一是用單變數的 Chi square、或是 information gain\n\n但 RFE 可以考慮到特徵之間的交互作用，缺點是需要較大的運算資源\n\n這點由於我們的資料集比較少而可以獲得緩解，在 Sklearn 上的實作也蠻簡單的","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"compare = ['Sex_Code', 'Pclass', 'FareBin_Code_4', 'FareBin_Code_5', 'FareBin_Code_6']\nselector = RFECV(RandomForestClassifier(n_estimators=250, min_samples_split=20), cv=10, n_jobs=-1)\nselector.fit(X[compare], Y)\nprint(selector.support_)\nprint(selector.ranking_)\nprint(selector.grid_scores_*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"在 CV 上可看到切分成 6 份可以得到比較高的 CV 分數\n\n但是還沒有考慮到模型的 random_state 以及 Cross-Validation 切分的方式\n\n必須小心謹慎的確認切成 6 份是否真的是最好的\n\n下面針對 CV 及模型的 random_state 進行實驗","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"score_b4, score_b5, score_b6 = [], [], []\nseeds = 10\nfor i in range(seeds):\n    diff_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=i)\n    selector = RFECV(RandomForestClassifier(random_state=i, n_estimators=250, min_samples_split=20), cv=diff_cv, n_jobs=-1)\n    selector.fit(X[compare], Y)\n    score_b4.append(selector.grid_scores_[2])\n    score_b5.append(selector.grid_scores_[3])\n    score_b6.append(selector.grid_scores_[4])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 畫圖","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# to np.array\nscore_list = [score_b4, score_b5, score_b6]\nfor item in score_list:\n    item = np.array(item*100)\n\n# plot\nfig = plt.figure(figsize= (18,8) )\nax = plt.gca()\nax.plot(range(seeds), score_b4,'-ok',label='bins = 4')\nax.plot(range(seeds), score_b5,'-og',label='bins = 5')\nax.plot(range(seeds), score_b6,'-ob',label='bins = 6')\nax.set_xlabel(\"Seed #\", fontsize = '14')\nax.set_ylim(0.783,0.815)\nax.set_ylabel(\"Accuracy\", fontsize = '14')\nax.set_title('bins = 4 vs bins = 5 vs bins = 6', fontsize='20')\nplt.legend(fontsize = 14,loc='upper right')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"上圖我們可以看出切分成 4 份的準確率較低\n\n6 份比 5 份稍微好一點，在 CV 的結果是這樣\n\n接下來分別將其提交到 Kaggle 上\n\n這段程式碼和上面 Base Model 差不多，直接顯示 oob 分數以及提交的結果","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"b4, b5, b6 = ['Sex_Code', 'Pclass','FareBin_Code_4'], ['Sex_Code','Pclass','FareBin_Code_5'],\\\n['Sex_Code','Pclass','FareBin_Code_6']\nb4_Model = RandomForestClassifier(random_state=2,n_estimators=250,min_samples_split=20,oob_score=True)\nb4_Model.fit(X[b4], Y)\nb5_Model = RandomForestClassifier(random_state=2,n_estimators=250,min_samples_split=20,oob_score=True)\nb5_Model.fit(X[b5], Y)\nb6_Model = RandomForestClassifier(random_state=2,n_estimators=250,min_samples_split=20,oob_score=True)\nb6_Model.fit(X[b6], Y)\nprint('b4 oob score :%.5f' %(b4_Model.oob_score_),'   LB_Public : 0.7790')\nprint('b5 oob score :%.5f '%(b5_Model.oob_score_),' LB_Public : 0.79425')\nprint('b6 oob score : %.5f' %(b6_Model.oob_score_), '  LB_Public : 0.77033')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"在排行榜上的分數反而是切分成 5 份最高分，而不是6份\n\n這個情況在 Titanic 這個資料集上很常見\n\n可能是某種過度的特徵工程所帶來的 overfitting\n\n特徵工程在數學上也可以想像成原始特徵的非線性轉換，僅僅是我們賦予了每一種特徵工程對應的意義\n\n最終都必須得在 CV 以及排行榜上測試\n\n將 b5_Model 提交至 Kaggle","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# Submit\nX_Submit = test_df.drop(labels=['PassengerId'], axis=1)\n\nb5_pred = b5_Model.predict(X_Submit[b5])\n\nsubmit = pd.DataFrame({'PassengerId': test_df['PassengerId'],\n                      'Survived': b5_pred.astype(int)})\nsubmit.to_csv('submit_b5.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Submit b6\nX_Submit = test_df.drop(labels=['PassengerId'], axis=1)\n\nb6_pred = b6_Model.predict(X_Submit[b6])\n\nsubmit = pd.DataFrame({'PassengerId': test_df['PassengerId'],\n                      'Survived': b6_pred.astype(int)})\nsubmit.to_csv('submit_b6.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 連結(Connected_Survival)\n這個特徵相當有意思，主要是發現了乘客持有相同的船票意味著他們可能是家人或是朋友\n\n而在訓練集上這些互相有連結的人常常是一起活下來或是一起喪命，從票根的特徵 Ticket 開始看起","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['Ticket'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"891 個票根資訊中\n\n獨立的有 681 項\n\n表示一定有乘客是持有相同的票根，這意味著他們可能一起分享某一區的座位......\n\n建立家庭人數特徵 (將兄弟姊妹數 SibSp + 父母小孩數 Parch + 1) 方便接下來的觀察","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Family_size\ndata_df['Family_size'] = data_df['SibSp'] + data_df['Parch'] + 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"建立持有相同票根的 DataFrame，顯示姓名、票價、艙位、家庭人數","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"deplicate_ticket = []\nfor tk in data_df.Ticket.unique():\n    tem = data_df.loc[data_df.Ticket == tk, 'Fare']\n    if tem.count() > 1:\n        deplicate_ticket.append(data_df.loc[data_df.Ticket == tk, ['Name', 'Ticket', 'Fare', 'Cabin', 'Family_size', 'Survived']])\ndeplicate_ticket = pd.concat(deplicate_ticket)\ndeplicate_ticket.head(14)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 編號 7, 24, 374, 567, 389\n* 該家族有可能是全部一起喪命的 (縱使有一個是測試集中的資料)\n* 也可以從姓名中看出，5 名成員皆為 Palsson 家族\n* 一位先生 (Mr.) 及兩位小姐 (Miss) 帶著兩位小男孩 (Master) 搭上了鐵達尼號，票根皆為349909，甚至票價也相同\n\n## 編號 8, 172, 869\n* 皆為 Johnson 家族的成員，兩位女性 (Mrs.及Miss) 帶著一位小男孩 (Master) 搭上了船\n* 這則是一個三位乘客皆存活的例子\n* 未必所有的群組都是同生同死 (如編號 3, 137)\n\n## 其他案例\n* 可以從編號 6, 146 的這個群組看出兩位一起搭船，但並非是親屬關係 (姓名中的姓氏不同)\n* 可以推定可能是朋友或是基於甚麼原因共同搭船的人，可能在船難發生時互相幫忙\n\n## 親屬關係認定\n* 可以透過家庭成員人數這個特徵來分類\n* Family_size = 1，但是又在群組內的，即非親屬關係，我們歸類為朋友; Family_size > 1 則為家人","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"friend_df = deplicate_ticket.loc[(deplicate_ticket.Family_size == 1) & (deplicate_ticket.Survived.notnull())].head(7)\nfamily_df = deplicate_ticket.loc[(deplicate_ticket.Family_size > 1) & (deplicate_ticket.Survived.notnull())].head(7)\ndisplay(friend_df, family_df)\nprint('people keep the same ticket: %.0f '%len(deplicate_ticket))\nprint('friends: %.0f '%len(deplicate_ticket[deplicate_ticket.Family_size == 1]))\nprint('families: %.0f '%len(deplicate_ticket[deplicate_ticket.Family_size > 1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"有約莫600位乘客和他人持有相同票根\n\n其中大概有75%為家庭出遊\n\n接著依照以觀察來創建一個新的特徵","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"deplicate_ticket = []\nfor tk in data_df.Ticket.unique():\n    tem = data_df.loc[data_df.Ticket == tk, 'Fare']\n    if tem.count() > 1:\n        deplicate_ticket.append(data_df.loc[data_df.Ticket == tk, ['Name', 'Ticket', 'Fare', 'Cabin', 'Family_size', 'Survived']])\ndeplicate_ticket = pd.concat(deplicate_ticket)\ndeplicate_ticket.head(14)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"希望上表中票根 `PC 17599` 中的乘客建立 Connected_Survival = 1\n\n以及票根 `17463` `349909` 中的乘客建立Connected_Survival = 0\n\n但還須要多考慮沒有生還資訊的乘客 (同個票根中 Survived 都是 NaN 在測試集中) 的乘客，將 Connected_Survival = 0.5\n\n* 過濾出重複的票根 : `if( len(df_grp) > 1)`\n* 如果群組中有人生還 則定義 Connected_Survival = 1 : `if(smax == 1.0):`\n* 沒有人生還，則定義 Connected_Survival = 0 : `if( smin == 0.0):`\n* 剩下的沒有生還資訊，定義 Connected_Survival = 0.5 : 程式碼第一行 `data_df['Connected_Survival'] = 0.5`","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# the same ticket family or friends\ndata_df['Connected_Survival'] = 0.5 # default \nfor _, grp_df in data_df.groupby('Ticket'):\n    if (len(grp_df) > 1):\n        for ind, row in grp_df.iterrows():\n            smax = grp_df.drop(ind)['Survived'].max()\n            smin = grp_df.drop(ind)['Survived'].min()\n            passID = row['PassengerId']\n            if (smax == 1.0):\n                data_df.loc[data_df['PassengerId'] == passID, 'Connected_Survival'] = 1\n            elif (smin==0.0):\n                data_df.loc[data_df['PassengerId'] == passID, 'Connected_Survival'] = 0\n#print\nprint('people keep the same ticket: %.0f '%len(deplicate_ticket))\nprint(\"people have connected information : %.0f\" \n      %(data_df[data_df['Connected_Survival']!=0.5].shape[0]))\ndata_df.groupby('Connected_Survival')[['Survived']].mean().round(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"得到 596 位彼此持有相同票根的乘客\n\n其中496位含有連結關係 (0 or 1 )\n\n將其分組分別計算生還率\n\n也還能把資料分的蠻開的，其中連結 =1 的生存率更是從 0.298 飆升至 0.728\n\n完成特徵工程，分離訓練集、測試集，並分離出生還與否 (Y) 以及訓練資料 (X)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = data_df[:len(train_df)]\ntest_df = data_df[len(train_df):]\n\n# Training set and labels\nX = train_df.drop(labels=['Survived', 'PassengerId'], axis=1)\nY = train_df['Survived']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"加入模型、訓練，觀察 oob score","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"connect = ['Sex_Code', 'Pclass', 'FareBin_Code_5', 'Connected_Survival']\nconnect_Model = RandomForestClassifier(random_state=2, n_estimators=250, min_samples_split=20,\n                                      oob_score=True)\nconnect_Model.fit(X[connect], Y)\nprint('connect oob score:%.5f' %(connect_Model.oob_score_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#submit\nX_Submit = test_df.drop(labels=['PassengerId'], axis=1)\n\nconnect_pred = connect_Model.predict(X_Submit[connect])\n\nsubmit = pd.DataFrame({'PassengerId': test_df['PassengerId'],\n                      'Survived': connect_pred.astype(int)})\n\nsubmit.to_csv('submit_connect.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 年齡\n在這個特徵中會面臨 20% 缺失值的問題\n\n和前面的票價 (Fare) 僅僅只有一項缺失值相比，缺的不少\n\n而這很有可能影響預測，分兩個部分來討論:\n\n截止目前為止，使用性別及艙等可以達到 0.76555 的準確率\n\n後來加入了 2 項特徵提升了 4%\n\n因此如果缺失年齡特別都屬於某個性別，或是特別都屬於某個艙等，就很有可能影響預測，以下觀察缺失值分佈的情況","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df['Has_Age'] = data_df['Age'].isnull().map(lambda x : 0 if x == True else 1)\nfig, [ax1, ax2] = plt.subplots(1, 2)\nfig.set_figwidth(18)\nax1 = sns.countplot(data_df['Pclass'],hue=data_df['Has_Age'],ax=ax1)\nax2 = sns.countplot(data_df['Sex'],hue=data_df['Has_Age'],ax=ax2)\npd.crosstab(data_df['Has_Age'],data_df['Sex'],margins=True).round(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 左圖\n* 左圖可以明顯的看出年齡缺失值蠻大部分在 3 等艙\n* 如果年齡真的是個重要特徵，則我們對 3 等艙的觀察就會失真\n* 保守的作法是觀察 1, 2 艙等中，年齡對存活與否的影響\n\n### 右圖\n* 顯示缺失值對性別的分布\n* 搭配表格看的話，466 位女性有 78 位缺失年齡 (16.7%)\n* 843 位男性有 185 位缺失年齡 (21.9%)，比例差了5%\n* 男性缺失年齡稍微多一點，如果年齡對生存與否有影響的話，可能可以搭配男性藉此被區分出更多的生還者 (例如男性小孩生還率有可能高於男性成人)\n\n1,2 艙之中，年齡對存活與否的影響:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Masks\nMask_Has_Age_P12_Survived = ((data_df.Has_Age == 1) & (data_df.Pclass != 3) & (data_df.Survived == 1))\nMask_Has_Age_P12_Dead = ((data_df.Has_Age == 1) & (data_df.Pclass != 3) & (data_df.Survived == 0))\n\n# Plot\nfig, ax = plt.subplots(figsize = (15, 9))\nax = sns.distplot(data_df.loc[Mask_Has_Age_P12_Survived, 'Age'], kde=False, bins=10, norm_hist=True, label='Survived')\nax = sns.distplot(data_df.loc[Mask_Has_Age_P12_Dead, 'Age'], kde=False, bins=10, norm_hist=True, label='Dead')\nax.legend()\nax.set_title('Age vs Survived in Pclass=1 and 2', fontsize=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"圖中可以看到，左邊藍色的部分多出了一塊，也就是這部分生存率較高的，約 <16 歲\n\n表示青少年以下 (包含小孩) 會有較高的生存率\n\n同時，其餘部分也顯示出了，若 >16 歲，基本上年齡不算是一個顯著的特徵來判定是否生還\n\n而 70~80 歲的這個區間，由於樣本數太少，因此不列入採計。\n\n綜合上述 3 張圖的討論\n\n找出那些 <16 歲的缺失值是重要的，這會影響預測\n\n而 >16 歲的部分則不採用，否則只是擬合了噪聲\n\n因此年齡這個特徵可以抽取出 <16 歲及 >16 歲做為一個 2 元特徵\n\n填入缺失值的方式我們選擇使用姓名當中的稱謂中位數來填補，比起填中位數要準確的多","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# extracted title using name\ndata_df['Title'] = data_df.Name.str.extract('([A-Za-z]+)\\.', expand=False)\ndata_df['Title'] = data_df['Title'].replace(['Capt', 'Col', 'Countess', 'Don', 'Dr', 'Dona', 'Jonkheer', 'Major','Rev','Sir'],'Rare')\ndata_df['Title'] = data_df['Title'].replace(['Mlle', 'Ms','Mme'],'Miss')\ndata_df['Title'] = data_df['Title'].replace(['Lady'],'Mrs')\ndata_df['Title'] = data_df['Title'].map({\"Mr\":0, \"Rare\" : 1, \"Master\" : 2,\"Miss\" : 3, \"Mrs\" : 4 })\nTi = data_df.groupby('Title')['Age'].median()\nTi","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"列表為年齡中位數，先生 - 29 歲，罕見稱謂 - 47 歲，小男孩 - 4 歲，小姐- 22 歲， 女士 - 36 歲\n\n不動原始特徵 Age，將填滿年齡的特徵創建為 Ti_Age，分為 <16 歲及 >16 歲，命名為 Ti_Minor","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Ti_pred = data_df.groupby('Title')['Age'].median().values\ndata_df['Ti_Age'] = data_df['Age']\n\n# Filling the missing age\nfor i in range(0, 5):\n    data_df.loc[(data_df.Age.isnull()) & (data_df.Title == i), 'Ti_Age'] = Ti_pred[i]\n    \ndata_df['Ti_Age'] = data_df['Ti_Age'].astype('int')\ndata_df['Ti_Minor'] = ((data_df['Ti_Age']) < 16.0) * 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"完成特徵工程，分離訓練集、測試集，分離出生還與否 (Y) 以及訓練資料 (X)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# split with new feature\ntrain_df = data_df[:len(train_df)]\ntest_df = data_df[len(train_df):]\n\n# Training set and labels\nX = train_df.drop(labels=['Survived', 'PassengerId'], axis=1)\nY = train_df['Survived']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"加入模型、訓練，觀察 oob score","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"minor = ['Sex_Code', 'Pclass', 'FareBin_Code_5', 'Connected_Survival', 'Ti_Minor']\nminor_Model = RandomForestClassifier(random_state=2, n_estimators=250, min_samples_split=20, oob_score=True)\nminor_Model.fit(X[minor], Y)\nprint('minor oob score: %.5f' %(minor_Model.oob_score_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# submit\nX_Submit = test_df.drop(labels=['PassengerId'], axis=1)\n\nminor_pred = minor_Model.predict(X_Submit[minor])\n\nsubmit = pd.DataFrame({'PassengerId': test_df['PassengerId'],\n                      'Survived': minor_pred.astype(int)})\n\nsubmit.to_csv('submit_minor.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"測試使用 XGBoost","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\n\nxgbc = XGBClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgbc.fit(X[minor], Y)\nprint('Accuracy:', xgbc.score(X[minor], Y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submit\nX_Submit = test_df.drop(labels=['PassengerId'], axis=1)\nxgbc_pred = xgbc.predict(X_Submit[minor])\nsubmit = pd.DataFrame({'PassengerId': test_df['PassengerId'],\n                      'Survived': xgbc_pred.astype(int)})\n\nsubmit.to_csv('submit_xgbc.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}